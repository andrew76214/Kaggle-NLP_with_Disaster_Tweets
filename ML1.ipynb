{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "a5aSwT9gY2Mn"
      },
      "outputs": [],
      "source": [
        "# Kaggle Comprtition URL\n",
        "# https://www.kaggle.com/competitions/nlp-getting-started/overview\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "dir_path = './data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TXaMwEpnY-FM"
      },
      "outputs": [],
      "source": [
        "# Load train/test data\n",
        "train_data = pd.read_csv(dir_path + 'train.csv')\n",
        "test_data = pd.read_csv(dir_path + 'test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0sfX0-LbZAXD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kTKxMLVxZCk4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3O5Xt63YWxCg"
      },
      "outputs": [],
      "source": [
        "#see if the text is positive or negative\n",
        "def get_sentiment(text):\n",
        "  analysis = TextBlob(text)\n",
        "  return analysis.sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QFeytcoMOEOv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean(text):\n",
        "  text = re.sub(r'https?://\\S+|www\\.\\S+', '', text) #remove URLs\n",
        "  text = re.sub(r'\\@|\\#|\\d+|[|]_-', '', text)\n",
        "  text = re.sub('<.*?>', '', text) #remove HTML\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JHpe_UlZbFQt"
      },
      "outputs": [],
      "source": [
        "train_data['clean_text']=train_data['text'].apply(clean)\n",
        "x_train = train_data['clean_text']\n",
        "y_train = train_data['target']\n",
        "\n",
        "#get the sentimet of the train text\n",
        "#train_data['sentiment'] = train_data['text'].apply(get_sentiment) #no change\n",
        "#test_data['sentiment'] = test_data['text'].apply(get_sentiment)\n",
        "\n",
        "#get the length of both text\n",
        "#train_data[\"text_length\"] = train_data[\"text\"].apply(len) #worse\n",
        "#test_data[\"text_length\"] = test_data[\"text\"].apply(len)\n",
        "\n",
        "test_data['clean_text']=test_data['text'].apply(clean)\n",
        "x_test = test_data['clean_text']\n",
        "\n",
        "train_data['text_length'] = train_data['text'].apply(len)\n",
        "train_data['word_count'] = train_data['text'].apply(lambda x: len(x.split()))\n",
        "test_data['text_length'] = test_data['text'].apply(len)\n",
        "test_data['word_count'] = test_data['text'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2H5NY-dUcRwV"
      },
      "outputs": [],
      "source": [
        "#ignore terms that are too frequent, remove stop words, and have ngrams\n",
        "count_vectorizer = CountVectorizer(max_df=0.5,ngram_range=(1,3),stop_words='english')\n",
        "\n",
        "x_train_vectors = count_vectorizer.fit_transform(x_train)\n",
        "x_test_vectors = count_vectorizer.transform(x_test)\n",
        "\n",
        "# Step 2: Encode 'keyword' using LabelEncoder (convert categorical to numeric)\n",
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "train_key = ohe.fit_transform(train_data[['keyword']])\n",
        "test_key = ohe.transform(test_data[['keyword']])\n",
        "\n",
        "numeric_features_train = csr_matrix(train_data[['text_length', 'word_count']].values)\n",
        "numeric_features_test = csr_matrix(test_data[['text_length', 'word_count']].values)\n",
        "\n",
        "#combin all vectors into matrix\n",
        "x_train_vectors = hstack([train_key,x_train_vectors,numeric_features_train])  #don't need this if don't use previous two\n",
        "x_test_vectors = hstack([test_key,x_test_vectors,numeric_features_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "j8gEgCf90nkV"
      },
      "outputs": [],
      "source": [
        "# see if there is difference between TfidfVectorizer and CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.5,ngram_range=(1,3),stop_words='english')\n",
        "\n",
        "x_tfidf_train_vectors = tfidf_vectorizer.fit_transform(x_train)\n",
        "x_tfidf_test_vectors = tfidf_vectorizer.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9cpD3UGYK85"
      },
      "source": [
        "## RidgeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nqcJE8YkdVlM"
      },
      "outputs": [],
      "source": [
        "# train the classifier to address overfitting and make predictions\n",
        "rclf = RidgeClassifier()\n",
        "rclf.fit(x_train_vectors,y_train)\n",
        "\n",
        "rclf_prediction = rclf.predict(x_test_vectors)\n",
        "\n",
        "# submission_data = pd.DataFrame({'id':test_data['id'], 'target':rclf_prediction})\n",
        "\n",
        "# submission_data.to_csv('RidgeClassifier_alpha7_submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRHixNKwqVY"
      },
      "source": [
        "Public score: 0.79344"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "rclf = RidgeClassifier(tol=0.01)\n",
        "rclf.fit(x_tfidf_train_vectors,y_train)\n",
        "\n",
        "rclf_tfidf_prediction = rclf.predict(x_tfidf_test_vectors)\n",
        "\n",
        "#submission_data = pd.DataFrame({'id':test_data['id'], 'target':rclf_tfidf_prediction})\n",
        "\n",
        "#submission_data.to_csv('RidgeClassifier_tfidf_tol0.01_submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Public score: 0.80324"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qmrSgQvUuml"
      },
      "source": [
        "## LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "2M_7KvLfUwTq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "logr = linear_model.LogisticRegression()\n",
        "logr.fit(x_train_vectors,y_train)\n",
        "logr_prediction = logr.predict(x_test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ceuVuoNfUUrm"
      },
      "outputs": [],
      "source": [
        "# submission_data = pd.DataFrame({'id':test_data['id'], 'target':logr_prediction})\n",
        "\n",
        "# submission_data.to_csv('LogisticRegression_submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "-RM2yXWjgLdi"
      },
      "outputs": [],
      "source": [
        "#testing different ways of regularization in LogisticRegression (reduce error and overfitting)\n",
        "l1_model = linear_model.LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=42, max_iter=1000)\n",
        "l2_model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, random_state=42, max_iter=1000)  #defult setting max_iter=1000 making it perform better than original\n",
        "#elastic_net_model = linear_model.LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, C=1.0, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "l1_model.fit(x_train_vectors,y_train)\n",
        "l2_model.fit(x_train_vectors,y_train)\n",
        "#elastic_net_model.fit(x_train_vectors,y_train)\n",
        "\n",
        "l1_model_pre = l1_model.predict(x_test_vectors)\n",
        "l2_model_pre = l2_model.predict(x_test_vectors)\n",
        "#elastic_net_model_pre = elastic_net_model.predict(x_test_vectors)\n",
        "\n",
        "# submission_data = pd.DataFrame({'id':test_data['id'], 'target':l1_model_pre})\n",
        "# submission_data.to_csv('LogrL1_submission.csv',index=False)\n",
        "\n",
        "# submission_data = pd.DataFrame({'id':test_data['id'], 'target':l2_model_pre})\n",
        "# submission_data.to_csv('LogrL2_submission.csv',index=False)\n",
        "\n",
        "#submission_data = pd.DataFrame({'id':test_data['id'], 'target':elastic_net_model_pre})\n",
        "#submission_data.to_csv('Logr_elastic_submission.csv',index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8WLEHP_cqDb"
      },
      "source": [
        "1. L1 Public score: 0.79313\n",
        "2. L2 Public score: 0.80110\n",
        "3. Elastic_net_model Public score: 0.79865\n",
        "4. L1_tfidf Public score: 0.76739\n",
        "5. L2_tfidf Public score: 0.80110"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfLTGLKYUWZx"
      },
      "source": [
        "check accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaDEmChQbAGp",
        "outputId": "18be716b-72c2-48d5-e476-84f8b68aa4db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8796498905908097\n",
            "Recall: 0.6194144838212635\n",
            "F1 Score: 0.7269439421338157\n"
          ]
        }
      ],
      "source": [
        "#Check the accuracy score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "y = train_data['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# y_test is the true labels and y_pred are the model's predictions\n",
        "X_train, X_val, y_train, y_test = train_test_split(x_tfidf_train_vectors, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Initialize and train the classifier\n",
        "#rclf = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, random_state=42, max_iter=1000)\n",
        "rclf.fit(X_train, y_train)\n",
        "\n",
        "# our prediction\n",
        "y_pred = rclf.predict(X_val)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYJlhJhTrUtz"
      },
      "source": [
        "Precision: 0.8217054263565892\n",
        "Recall: 0.6533127889060092\n",
        "F1 Score: 0.7278969957081545"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(x_train_vectors,y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\anaconda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:25:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1分數: 0.7351063829787235\n",
            "voting:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.92      0.84      1446\n",
            "           1       0.85      0.65      0.74      1067\n",
            "\n",
            "    accuracy                           0.80      2513\n",
            "   macro avg       0.81      0.78      0.79      2513\n",
            "weighted avg       0.81      0.80      0.80      2513\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 定義多個模型\n",
        "# param_grid = {\n",
        "#     'max_depth': [3, 5, 10, None],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4]\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, scoring='f1', cv=5)\n",
        "# grid_search.fit(Xtrain, ytrain)\n",
        "\n",
        "# best_tree_clf = grid_search.best_estimator_\n",
        "log_reg = LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, random_state=42, max_iter=1000,class_weight='balanced')\n",
        "rg_clf = RidgeClassifier(alpha= 7, tol= 0.0001,class_weight='balanced')\n",
        "xgb_clf = XGBClassifier(\n",
        "    objective='binary:logistic',  # 二元分類任務\n",
        "    eval_metric='logloss',       # 評估指標，可以換成 'auc' 或 'error'\n",
        "    use_label_encoder=False,     # 避免警告\n",
        "    n_estimators=500,            # 樹的數量\n",
        "    learning_rate=0.3,           # 學習率\n",
        "    max_depth=5,                 # 樹的最大深度\n",
        "    random_state=42\n",
        ")\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100,           # Number of trees in the forest\n",
        "    max_depth=10,               # Max depth of each tree\n",
        "    random_state=42,\n",
        "    class_weight='balanced'     # Optional: Balance the classes in the dataset\n",
        ")\n",
        "#tree_clf = DecisionTreeClassifier(criterion='entropy',max_depth=100,min_samples_leaf=1,min_samples_split=50,random_state=42)\n",
        "\n",
        "\n",
        "# 投票分類器\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('log_reg', log_reg), ('rg', rg_clf),('xgb',xgb_clf),('rf',rf_clf)], #, ('tree', best_tree_clf)\n",
        "    voting='hard',\n",
        ")\n",
        "\n",
        "# 訓練與評估\n",
        "voting_clf.fit(Xtrain, ytrain)\n",
        "y_pred = voting_clf.predict(Xtest)\n",
        "\n",
        "print(f\"F1分數: {f1_score(ytest, y_pred)}\")\n",
        "print(\"voting:\",classification_report(ytest,y_pred))\n",
        "\n",
        "# voting_clf.fit(x_train_vectors, y)\n",
        "# y_pre = voting_clf.predict(x_test_vectors)\n",
        "# submission_data = pd.DataFrame({'id':test_data['id'], 'target':y_pre})\n",
        "# submission_data.to_csv('voting_submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "public score:0.80171   (舊程式分數有比較高0.80447 但我找不回來)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
